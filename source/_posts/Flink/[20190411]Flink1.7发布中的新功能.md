---
layout: post
author: sjf0115
title: Flink1.7发布中的新功能
date: 2019-02-18 20:08:12
tags:
  - Flink

categories: Flink
permalink: apache-flink-1-7-0-release
---

Apache Flink 社区正式宣布 Apache Flink 1.7.0 发布。最新版本包括解决了420多个问题以及令人兴奋的新增功能，我们将在本文进行描述。有关更多的详细信息请查看[完整目录](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12315522&version=12343585)。

Flink 1.7.0 版本与 1.xy 版本使用 `@Public` 注解注释的API兼容。该版本现已上市，我们鼓励大家下载该[版本](http://flink.apache.org/downloads.html)并查看更新的[文档](https://ci.apache.org/projects/flink/flink-docs-release-1.7/)。

### 1. Flink 1.7.0 - 扩展流处理的范围

在 Flink 1.7.0，我们更关注实现快速数据处理以及以无缝方式为 Flink 社区构建数据密集型应用程序。我们最新版本包括一些令人兴奋的新功能和改进，例如对 Scala 2.12 的支持，Exactly-Once 语义的 S3 文件接收器，复杂事件处理与流SQL的集成，更多的功能我们在下面解释。

### 2. 新功能与改进

#### 2.1 Flink中的Scala 2.12支持

> [FLINK-7811](https://issues.apache.org/jira/browse/FLINK-7811)

Flink 1.7.0 是第一个完全支持 Scala 2.12 的版本。这可以让用户使用新的 Scala 版本编写 Flink 应用程序以及利用 Scala 2.12 的生态系统。

#### 2.2 状态变化

> [FLINK-9376](https://issues.apache.org/jira/browse/FLINK-9376)

在许多情况下，由于需求的变化，长期运行的 Flink 应用程序会在其生命周期内发生变化。在不丢失当前应用程序进度状态的情况下更改用户状态是应用程序变化的关键要求。Flink 1.7.0 版本中社区添加了状态变化，允许我们灵活地调整长时间运行的应用程序的用户状态模式，同时保持与先前保存点的兼容。通过状态变化，我们可以在状态模式中添加或删除列。当使用 Avro 生成类作为用户状态时，状态模式变化可以开箱即用，这意味着状态模式可以根据 Avro 的规范进行变化。虽然 Avro 类型是 Flink 1.7 中唯一支持模式变化的内置类型，但社区仍在继续致力于在未来的 Flink 版本中进一步扩展对其他类型的支持。
> evolution 译为 变化

#### 2.3 Exactly-once语义的S3 StreamingFileSink

> [FLINK-9752](https://issues.apache.org/jira/browse/FLINK-9752)

Flink 1.6.0 中引入的 StreamingFileSink 现在已经扩展到 S3 文件系统，并保证 Exactly-once 语义。使用此功能允许所有 S3 用户构建写入 S3 的 Exactly-once 语义端到端管道。

#### 2.4 Streaming SQL中支持MATCH_RECOGNIZE

> [FLINK-6935](https://issues.apache.org/jira/browse/FLINK-6935)

这是 Apache Flink 1.7.0 的一个重要补充，它为 Flink SQL 提供了 MATCH_RECOGNIZE 标准的初始支持。此功能融合了复杂事件处理（CEP）和SQL，可以轻松地对数据流进行模式匹配，从而实现一整套新的用例。此功能目前处于测试阶段。

#### 2.5 Streaming SQL中的 Temporal Tables 和 Temporal Joins

> [FLINK-9712](https://issues.apache.org/jira/browse/FLINK-9712)

Temporal Tables 是 Apache Flink 中的一个新概念，它为表的更改历史记录提供（参数化）视图，可以返回表在任何时间点的内容。例如，我们可以使用具有历史货币汇率的表。随着时间的推移，表会不断发生变化，并增加更新的汇率。Temporal Table 是一种视图，可以返回汇率在任何时间点的实际状态。通过这样的表，可以使用正确的汇率将不同货币的订单流转换为通用货币。

Temporal Joins 允许 Streaming 数据与不断变化/更新的表的内存和计算效率的连接，使用处理时间或事件时间，同时符合ANSI SQL。

流式 SQL 的其他功能除了上面提到的主要功能外，Flink 的 Table＆SQL API 已经扩展到更多用例。以下内置函数被添加到API：`TO_BASE64`，`LOG2`，`LTRIM`，` REPEAT`，`REPLACE`，`COSH`，`SINH`，`TANH`。SQL Client 现在支持在环境文件和 CLI 会话中自定义视图。此外，CLI 中还添加了基本的 SQL 语句自动完成功能。社区添加了一个 Elasticsearch 6 table sink，允许存储动态表的更新结果。

#### 2.6 版本化REST API

> [FLINK-7551](https://issues.apache.org/jira/browse/FLINK-7551)

从 Flink 1.7.0 开始，REST API 已经版本化。这保证了 Flink REST API 的稳定性，因此可以在 Flink 中针对稳定的 API开发第三方应用程序。因此，未来的 Flink 升级不需要更改现有的第三方集成。

#### 2.7 Kafka 2.0 Connector

> [FLINK-10598](https://issues.apache.org/jira/browse/FLINK-10598)

Apache Flink 1.7.0 继续添加更多的连接器，使其更容易与更多外部系统进行交互。在此版本中，社区添加了 Kafka 2.0 连接器，可以从 Kafka 2.0 读写数据时保证 Exactly-Once 语义。

#### 2.8 本地恢复

> [FLINK-9635](https://issues.apache.org/jira/browse/FLINK-9635)

Apache Flink 1.7.0 通过扩展 Flink 的调度来完成本地恢复功能，以便在恢复时考虑之前的部署位置。如果启用了本地恢复，Flink 将在运行任务的机器上保留一份最新检查点的本地副本。将任务调度到之前的位置，Flink 可以通过从本地磁盘读取检查点状态来最小化恢复状态的网络流量。此功能大大提高了恢复速度。

#### 2.9 删除Flink的传统模式

> [FLINK-10392](https://issues.apache.org/jira/browse/FLINK-10392)

Apache Flink 1.7.0 标志着 Flip-6 工作已经完全完成并且与传统模式达到功能奇偶校验。因此，此版本删除了对传统模式的支持。

原文: [What’s new in the latest Apache Flink 1.7.0 release](https://www.ververica.com/blog/apache-flink-1-7-0-release)
