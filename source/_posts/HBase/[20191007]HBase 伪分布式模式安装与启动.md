---
layout: post
author: sjf0115
title: HBase 伪分布式模式安装与启动
date: 2019-10-07 17:08:01
tags:
  - HBase

categories: HBase
permalink: hbase-pseudo-distributed-setup-and-start
---

## 1. 环境相关

安装 HBase 之前默认我们已经完成了 Hadoop、ZooKeeper 安装，如果还没有安装可以参考如下博文：
- [Hadoop 安装与启动](http://smartsi.club/hadoop-setup-and-start.html)
- [ZooKeeper 伪集群模式安装与启动](http://smartsi.club/zookeeper-standalone-setup-and-run.html)

集群配置：
- JDK: 1.8.0
- Hadoop：2.7.7
- ZooKeeper：3.4.12
- HBase：2.1.6

### 1.1 Java

下表总结了在各种 Java 版本上部署 HBase 的建议。对号符号标示测试的基准以及愿意帮助诊断和解决您可能遇到的问题。类似地，叹号和叉号符号通常表示您在遇到问题时，需要更改 Java 环境。

> HBase建议下游用户使用来自OpenJDK项目或供应商的标记为长期支持（LTS）的JDK版本。 截至2018年3月，这意味着Java 8是唯一适用的版本。

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/HBase/hbase-pseudo-distributed-setup-and-start-1.jpg?raw=true)

我们必须在集群的每个节点上设置 `JAVA_HOME`。`hbase-env.sh` 提供了一种方便的机制来执行此操作。

### 1.2 Hadoop

下表总结了每个 HBase 版本支持的 Hadoop 版本。基于 HBase 版本，我们需要选择最合适的 Hadoop 版本。我们可以使用 Apache Hadoop 或供应商的 Hadoop 发行版。该表中未出现的较旧版本不在支持，并且可能缺少必要的功能，而较新版本未经测试，但可以试用：
![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/HBase/hbase-pseudo-distributed-setup-and-start-2.jpg?raw=true)

- 对号符号标示经过测试并且功能齐全。
- 叉号符号已知功能不完整或存在[CVE](https://hadoop.apache.org/cve_list.html)，因此我们在较新的次要版本中放弃了对它的支持。
- 叹号符号未经测试，可能/可能不起作用。

> 推荐使用 Hadoop2.x。Hadoop 2.x 速度更快，并且具有短路读取（请参阅利用本地数据）等功能，这将有助于改善 HBase 随机读取配置文件。Hadoop 2.x 还包括重要的 bug 修复，这些改进将改善我们 HBase 整体体验。HBase 不支持与 Hadoop 的早期版本一起运行。

由于 HBase 依赖 Hadoop，它配套发布了一个 Hadoop jar 文件在它的 lib 目录下。该套装 jar 仅用于独立模式。在分布式模式下，Hadoop 版本必须和 HBase 下的版本一致。用你运行的分布式 Hadoop 版本 jar 文件替换 HBase lib 目录下的 Hadoop jar 文件，以避免版本不匹配问题。确认替换了集群中所有 HBase 下的 jar 文件。Hadoop 版本不匹配问题有不同表现，但看起来都像挂掉了。

#### 1.2.1 dfs.datanode.max.transfer.threads

一个 Hadoop HDFS Datanode 有一个同时处理文件的上限。进行任何加载之前，请确保已配置 Hadoop 的 `conf/hdfs-site.xml` 文件，并将 `dfs.datanode.max.transfer.threads` 值至少设置为以下值：
```xml
<property>
  <name>dfs.datanode.max.transfer.threads</name>
  <value>4096</value>
</property>
```
完成上述配置后，请务必重新启动HDFS。如果没有进行配置，则会导致如下奇怪异常。例如：
```
10/12/08 20:10:31 INFO hdfs.DFSClient: Could not obtain block
    blk_XXXXXXXXXXXXXXXXXXXXXX_YYYYYYYY from any node: java.io.IOException: No live nodes
    contain current block. Will get new block locations from namenode and retry...
```
另请参阅 [casestudies.max.transfer.threads](https://hbase.apache.org/book.html#casestudies.max.transfer.threads)，并请注意，此属性以前称为 `dfs.datanode.max.xcievers`（例如，[Hadoop HDFS: Deceived by Xciever](http://ccgtech.blogspot.com/2010/02/hadoop-hdfs-deceived-by-xciever.html)）。

### 1.3 ZooKeeper

使用 ZooKeeper 3.4.x 以上版本。ZooKeeper 也可以不用自己安装，使用内置的 ZooKeeper。

## 2. 下载解压HBase

选择一个 Apache 下载镜像，下载 HBase Releases。下载后缀为 `.tar.gz` 的文件，例如，`hbase-2.1.6-bin.tar.gz`。解压缩到我们的工作目录 `~/opt`:
```
tar -zxvf hbase-2.1.6-bin.tar.gz -C ~/opt/
```
为了便于以后的升级，我们需要创建一个软连接:
```
ln -s hbase-2.1.6 hbase
```
修改 `/etc/profile` 配置环境变量：
```
export HBASE_HOME=/Users/smartsi/opt/hbase
export PATH=${HBASE_HOME}/bin:$PATH
```

## 3. 运行模式

HBase 有两种运行模式：独立运行和分布式集群运行。开箱即用，HBase 以独立模式运行。无论使用哪种模式，都需要通过编辑 HBase conf 目录中的文件来配置 HBase。至少，我们必须编辑 `conf/hbase-env.sh` 以告知 HBase 使用的 Java。在此文件中，我们需要设置 HBase 环境变量，例如 JVM 的堆大小已经其他选项等。将 `JAVA_HOME` 设置为指向 Java 安装的根目录。

### 3.1 独立运行模式

这是默认部署模式。在独立模式下，HBase 不使用 HDFS，而是使用本地文件系统。所有 HBase 守护程序和本地 ZooKeeper 都运作在一个 JVM 中。ZooKeeper 监听一个端口，这样客户端就可以连接 HBase 了。

我们经常使用的独立运行模式是，不是持久化到本地文件系统，而是持久化到 HDFS 实例。要配置此独立模式，需要编辑 `hbase-site.xml` 文件配置 `hbase.rootdir` 以指向 HDFS 实例中的目录，然后将 `hbase.cluster.distributed` 设置为 `false`。例如：
```xml
<configuration>
  <property>
    <name>hbase.rootdir</name>
    <value>hdfs://localhost:8020/hbase</value>
  </property>
  <property>
    <name>hbase.cluster.distributed</name>
    <value>false</value>
  </property>
</configuration>
```

### 3.2 伪分布式集群模式

可以将分布式模式细分为
- 伪分布式模式，所有守护程序都在单个节点上运行。
- 全分布式模式，完全分布在集群中的所有节点上。

伪分布式模式可以针对本地文件系统运行，也可以针对 Hadoop 分布式文件系统（HDFS）实例运行。全分布式模式只能在 HDFS 上运行。

伪分布式模式意味着 HBase 仍完全在单个节点上运行，但是每个 HBase 守护程序（HMaster，HRegionServer和ZooKeeper）作为单独的进程运行：在独立模式下，所有守护程序都在一个 JVM 进程/实例中运行。

## 4. 配置

在启动 HBase 之前，必须设置 `JAVA_HOME` 环境变量。为了使此操作更容易，HBase 允许我们在 `conf/hbase-env.sh` 文件中进行设置。我们必须找到机器上 Java 安装的位置，如果我们不知道其位置，可以使用 `whereis java` 命令寻找。找到位置后，编辑 `conf/hbase-env.sh` 文件，并取消注释以 `#export JAVA_HOME =` 开头的行，然后将其设置为 Java 安装路径。

配置 hbase-env.sh：
```
# JAVA安装路径
export JAVA_HOME=${JAVA_HOME}
# HBase的日志路径，默认为logs目录，可以不用配置
export HBASE_LOG_DIR=${HBASE_HOME}/logs
# HBase的pids目录
export HBASE_PID_DIR=${HBASE_HOME}/pids
# 是否使用外部zk，true表示使用自带zk
export HBASE_MANAGES_ZK=false
```

编辑 `conf/hbase-site.xml`，这是主要的 HBase 配置文件。首先，添加以下属性，该属性指示 HBase 以分布式模式运行，每个守护程序一个 JVM 实例:
```xml
<property>
  <name>hbase.cluster.distributed</name>
  <value>true</value>
</property>
```
接下来，使用 `hdfs:////URI` 语法将 `hbase.rootdir` 从本地文件系统更改为 `HDFS` 实例的地址。在此示例中，HDFS 在本地主机上的 9000 端口上运行。请确保删除 `hbase.unsafe.stream.capability.enforce` 的条目或将其设置为 `true`:
```xml
<property>
  <name>hbase.rootdir</name>
  <value>hdfs://localhost:9000/hbase</value>
</property>
```
> 我们无需在 HDFS 中创建 hbase 目录。HBase 会为我们完成此工作。如果我们自己创建了目录，那么 HBase 将尝试进行迁移，这并不是我们想要的。

> hbase.rootdir 里面的 HDFS 地址是要跟 Hadoop 的 core-site.xml 里面的 fs.defaultFS 的 HDFS 的 IP 地址或者域名、端口必须一致

实际上，我们应该仔细考虑我们的 ZooKeeper 配置。此配置将指导 HBase 在集群的每个节点上启动和管理 ZooKeeper 实例。我们需要在本地文件系统上指定 ZooKeeper 写入数据的目录，ZooKeeper的 zoo.conf 中的配置（dataDir所设定的位置）：
```xml
<property>
    <name>hbase.zookeeper.property.dataDir</name>
    <value>/Users/smartsi/opt/zookeeper/data</value>
</property>
```
在这里我们使用外部 zookeeper，如果使用外部 ZK，hbase-env.sh 中属性 `HBASE_MANAGES_ZK` 必须设置为false，ZK数量必须为奇数，多个可用逗号分隔：
```xml
<property>  
  <name>hbase.zookeeper.quorum</name>  
  <value>localhost</value>
</property>
```

服务器在重启时都要删除 /tmp 目录下的内容，因此我们应该将数据存储在其他位置。以下配置会将 HBase 的数据存储在名为 smartsi 的用户的主目录中的 `opt/hbase/tmp` 目录下:
```xml
<property>
    <name>hbase.tmp.dir</name>
    <value>/Users/smartsi/opt/hbase/tmp</value>
</property>
```

配置hbase-site.xml：
```xml
<configuration>
  <property>
      <name>hbase.rootdir</name>
      <value>hdfs://localhost:9000/hbase</value>
  </property>

  <property>
      <name>hbase.cluster.distributed</name>
      <value>true</value>
  </property>

  <property>
      <name>hbase.tmp.dir</name>
      <value>/Users/smartsi/opt/hbase/tmp</value>
  </property>

  <property>
      <name>hbase.zookeeper.property.dataDir</name>
      <value>/Users/smartsi/opt/zookeeper/data</value>
  </property>

  <property>  
    <name>hbase.zookeeper.quorum</name>  
    <value>localhost</value>
  </property>
</configuration>
```

## 5. 运行

确保首先运行 HDFS。通过在 HADOOP_HOME 目录中运行 `bin/start-hdfs.sh` 来启动和停止 Hadoop HDFS 守护程序。我们可以通过将文件上传到 Hadoop 文件系统中以及获取上传内容来确保 HDFS 正确启动。HBase 通常不使用 MapReduce 或 YARN 守护程序。这些可以不需要启动。

如果我们使用的是自己的 ZooKeeper，需要启动并确认其正常运行，否则 HBase 将在启动过程中为我们启动内置的 ZooKeeper。

使用以下命令启动 HBase：
```
bin/start-hbase.sh
```
> 在 HBASE_HOME目录下运行以上命令。

使用上述命令启动 HBase。如果系统配置正确，那么 jps 命令应显示正在运行的 HMaster 和 HRegionServer 进程。现在，我们应该有一个正在运行的 HBase 实例。HBase 日志可在 logs 子目录中找到。

默认情况下，Web UI 部署在 Master 上的 16010 端口上（HBase RegionServers 默认在 16020 端口上侦听，并在 16030 端口上建立一个信息性HTTP服务器）。如果 Master 在默认端口上的名为 master.example.org 的主机上运行，可以访问 `http://master.example.org:16010` 以查看Web界面。

使用以下命令停止 HBase：
```
bin/stop-hbase.sh
```
停止可能需要一些时间才能完成。如果集群由许多机器组成，那么可能需要更长的时间。如果我们正在运行分布式操作，请确保等到 HBase 完全关闭后再停止 Hadoop 守护程序。

## 6. 验证

我们可以使用 jps 命令来验证我们是否有名为 HMaster、HRegionServer 的正在运行的进程:
```
smartsi:hadoop smartsi$ jps
47876 HRegionServer
47790 HMaster
...
```
我们可以通过浏览器访问 `http://localhost:16010` 来查看HBase Web UI。
![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/HBase/hbase-pseudo-distributed-setup-and-start-3.jpg?raw=true)

另外我们还可以检查 HDFS 中的 HBase 目录。如果一切正常，HBase 将在 HDFS 中创建其目录。在上面的配置中，它存储在 HDFS 上的 /hbase/ 目录中。我们可以在 Hadoop 的 bin/ 目录中使用 hadoop fs 命令列出该目录:
```
smartsi:hadoop smartsi$ hadoop fs -ls /hbase
Found 12 items
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/.hbck
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/.tmp
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/MasterProcWALs
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/WALs
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/archive
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/corrupt
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/data
-rw-r--r--   1 smartsi supergroup 42 2019-10-07 17:35 /hbase/hbase.id
-rw-r--r--   1 smartsi supergroup 7 2019-10-07 17:35 /hbase/hbase.version
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/mobdir
drwxr-xr-x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/oldWALs
drwx--x--x   - smartsi supergroup 0 2019-10-07 17:35 /hbase/staging
```

## 7. 使用

使用 hbase shell 命令连接到正在运行的 HBase 实例，该命令位于 HBase 安装目录的 bin/ 目录中。在此示例中，省略了启动 HBase Shell 时打印的一些用法和版本信息。HBase Shell 提示符以>字符结束：
```
smartsi:hbase smartsi$ ./bin/hbase shell
hbase(main):001:0>
```
使用 create 命令创建一个新表。我们必须指定表名称和列族名称：
```
hbase(main):001:0> create 'test', 'cf'
Created table test
Took 1.2144 seconds
=> Hbase::Table - test
hbase(main):002:0>
```
使用 list 命令确认表是否存在：
```
hbase(main):002:0> list 'test'
TABLE
test
1 row(s)
Took 0.0378 seconds
=> ["test"]
```
使用 put 命令将数据放入表中：
```
hbase(main):005:0> put 'test', 'row1', 'cf:a', 'value1'
Took 0.1687 seconds
```
从 HBase 获取数据的一种方法是扫描。使用 scan 命令扫描表中的数据：
```
hbase(main):008:0> scan 'test'
ROW                                                 COLUMN+CELL
 row1                                               column=cf:a, timestamp=1570442045109, value=value1
1 row(s)
Took 0.0038 seconds
```

欢迎关注我的公众号和博客：

![](https://github.com/sjf0115/PubLearnNotes/blob/master/image/Other/smartsi.jpg?raw=true)

参考: [Apache HBase ™ Reference Guide](https://hbase.apache.org/book.html#quickstart)
